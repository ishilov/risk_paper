{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "from math import sqrt\n",
    "import scipy.stats as sts\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from supplement_package import game\n",
    "from supplement_package import variables_pecan\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplement_package.game.stackelberg import StackelbergPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "\n",
    "from supplement_package.gurobi_implementation.gurobi import GurobiSolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preliminaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_keys = [661, 1642, 2335, 2361, 2818, 3039, 3456, 3538, 4031, 4373, 4767, 5746, 6139, 7536, 7719, 7800, 7901, 7951, 8156, 8386, 8565, 9019, 9160, 9922, 9278]\n",
    "\n",
    "dataframe_dict = dict()\n",
    "for key in agent_keys:\n",
    "    dataframe_dict.update({key : pd.read_csv('/Users/ishilov/Documents/risk_paper/risk_paper/data/df_{}.csv'.format(key))})\n",
    "\n",
    "community_size = len(dataframe_dict)\n",
    "\n",
    "for key in agent_keys:\n",
    "    cond_min = (dataframe_dict[key]['demand'].quantile(0.001) <= dataframe_dict[key]['demand'])\n",
    "    cond_max = (dataframe_dict[key]['demand'] <= dataframe_dict[key]['demand'].quantile(0.999))\n",
    "    dataframe_dict[key] = dataframe_dict[key][cond_min & cond_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_params(sample_size, community_size):\n",
    "    res = {}\n",
    "\n",
    "    for sample in range(sample_size):\n",
    "        A_tilde = [random.uniform(0,1) for i in range(community_size)]\n",
    "        B_tilde = [random.uniform(0,1) for i in range(community_size)]\n",
    "\n",
    "        a = [random.uniform(0,1) for i in range(community_size)]\n",
    "        b = [random.uniform(0,1) for i in range(community_size)]\n",
    "        d = [random.uniform(0,1) for i in range(community_size)]\n",
    "\n",
    "        #d_target = [[random.uniform(0,8) for j in range(len(probabilities))] for i in range(community_size)]\n",
    "        #g_res = [[random.uniform(0,3) for j in range(len(probabilities))] for i in range(community_size)]\n",
    "\n",
    "        #g_res = np.array(g_res)\n",
    "        #d_target = np.array(d_target)\n",
    "\n",
    "        risk_aversion = [random.uniform(0,1) for i in range(community_size)]\n",
    "\n",
    "        res.update({sample : {'A_tilde' : A_tilde,\n",
    "                        'B_tilde' : B_tilde,\n",
    "                        'a' : a,\n",
    "                        'b' : b,\n",
    "                        'd' : d,\n",
    "                        'risk_aversion' : risk_aversion}})\n",
    "\n",
    "    res_reformed = {(i, key) : res[i][key] for i in range(sample_size) for key in res[0].keys()}\n",
    "    mindx = pd.MultiIndex.from_tuples(res_reformed.keys())\n",
    "    df = pd.DataFrame(list(res_reformed.values()), index = mindx)\n",
    "    df.to_csv(f'../data/param_{sample_size}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_adj_matrix(matrix_path):\n",
    "    res = []\n",
    "    with open(matrix_path) as file:\n",
    "        for s in file:\n",
    "            string = ''.join(s.strip().strip(',').split(', '))\n",
    "            lst_temp = [int(sym) for sym in string]\n",
    "\n",
    "            res.append(lst_temp)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_new_params(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df_param(sample_size):\n",
    "    df_param = pd.read_csv(f'../data/param_{sample_size}.csv')\n",
    "    df_param.rename({'Unnamed: 0' : 'Sample', 'Unnamed: 1' : 'Parameter'}, axis=1, inplace= True)\n",
    "    df_param.set_index(['Sample', 'Parameter'], inplace=True)\n",
    "\n",
    "    return df_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_build(sample_size, agent_keys):\n",
    "    res = {}\n",
    "    \n",
    "    for key in agent_keys:\n",
    "        #chunks_demand = int(demand_dict[key][0].size / sample_size)\n",
    "        #chunks_generation = int(solar_dict[key][0].size / sample_size)\n",
    "\n",
    "\n",
    "        #probas_demand = [np.trapz(demand_dict[key][1][i * sample_size : (i + 1) * sample_size],\n",
    "        #                            demand_dict[key][0][i * sample_size : (i + 1) * sample_size])\n",
    "        #                            for i in range(chunks_demand)]\n",
    "\n",
    "        #probas_generation = [np.trapz(generation_dict[key][1][i * sample_size : (i + 1) * sample_size],\n",
    "        #                            generation_dict[key][0][i * sample_size : (i + 1) * sample_size])\n",
    "        #                            for i in range(chunks_generation)]\n",
    "\n",
    "        #res_demand = plt.hist(np.random.choice(demand_dict[key][0], size = sample_size, p = probabilities), bins = int(sample_size / 2))\n",
    "        #probas_update = res_demand[0] / res_demand[0].sum() if key == 661 else res[661]['probabilities']\n",
    "        #res.update({key : \n",
    "        #            {'values' : res_demand[1], \n",
    "        #            'probabilities' : probas_update}})\n",
    "\n",
    "        hist_demand = plt.hist(dataframe_dict[key]['demand'], bins = sample_size)\n",
    "        probas_demand, values_demand = hist_demand[0], hist_demand[1]\n",
    "        probas_demand = probas_demand / probas_demand.sum()\n",
    "\n",
    "        if 'solar' in dataframe_dict[key].columns:\n",
    "            hist_solar = plt.hist(dataframe_dict[key][dataframe_dict[key]['solar'] >= 0]['solar'], bins = sample_size)\n",
    "            probas_solar , values_solar  = hist_solar[0], hist_solar[1]\n",
    "            probas_solar = probas_demand / probas_demand.sum()\n",
    "\n",
    "        res.update({key : \n",
    "                    {'probas_demand' : probas_demand,\n",
    "                    'values_demand' : values_demand,\n",
    "                    'probas_solar' : probas_solar,\n",
    "                    'values_solar' : values_solar}})\n",
    "\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_sampling(sample_size, agent_keys, main_key = 661):\n",
    "    distribution = distribution_build(sample_size, agent_keys)\n",
    "\n",
    "    probabilities = distribution[main_key]['probas_demand']\n",
    "\n",
    "    d_target = []\n",
    "    g_res = []\n",
    "    for key in agent_keys:\n",
    "        d_target.append(distribution[key]['values_demand'][:-1])\n",
    "        g_res.append(distribution[key]['values_solar'][:-1])\n",
    "\n",
    "    return probabilities, d_target, g_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_input(df, index = 0):\n",
    "    A_tilde = list(df.loc[index].loc['A_tilde'])\n",
    "    B_tilde = list(df.loc[index].loc['B_tilde'])\n",
    "    a = list(df.loc[index].loc['a'])\n",
    "    b = list(df.loc[index].loc['b'])\n",
    "    d = list(df.loc[index].loc['d'])\n",
    "    risk_aversion = list(df.loc[index].loc['risk_aversion'])\n",
    "\n",
    "    for i, RA in enumerate(risk_aversion):\n",
    "        if RA > 0.95:\n",
    "            risk_aversion[i] = risk_aversion[i] - 0.1\n",
    "\n",
    "    return A_tilde, B_tilde, a, b, d, risk_aversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_amount = 2000\n",
    "\n",
    "#generate_new_params(param_amount,community_size=community_size)\n",
    "df_param = read_df_param(param_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_to_csv(scenario_amount, probabilities, d_target, g_res):\n",
    "    pd.DataFrame(d_target).to_csv(f'../data/df_d_target_{scenario_amount}.csv')\n",
    "    pd.DataFrame(g_res).to_csv(f'../data/df_g_res_{scenario_amount}.csv')\n",
    "    pd.DataFrame(probabilities).to_csv(f'../data/df_probabilities_{scenario_amount}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_csv(scenario_amount):\n",
    "    df_d_target = pd.read_csv(f'../data/df_d_target_{scenario_amount}.csv').drop('Unnamed: 0', axis = 1)\n",
    "    df_g_res = pd.read_csv(f'../data/df_g_res_{scenario_amount}.csv').drop('Unnamed: 0', axis = 1)\n",
    "    df_probabilities =pd.read_csv('../data/df_probabilities_100.csv').drop('Unnamed: 0', axis = 1)\n",
    "    \n",
    "    probabilities = df_probabilities.values.squeeze()\n",
    "\n",
    "\n",
    "    d_target = []\n",
    "    for _, row in df_d_target.iterrows():\n",
    "        d_target.append(row.values)\n",
    "\n",
    "    g_res = []\n",
    "    for _, row in df_g_res.iterrows():\n",
    "        g_res.append(row.values)\n",
    "\n",
    "    return probabilities, d_target, g_res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities, d_target, g_res = sample_from_csv(100)\n",
    "#A_tilde, B_tilde, a, b, d, risk_aversion = param_input(df_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agents_list_optimistic_total(A_tilde, B_tilde, a, b, d, risk_aversion, probabilities, connection_matrix, d_target, g_res):\n",
    "    agents = []\n",
    "    StackelbergPlayer.community_size = community_size\n",
    "    StackelbergPlayer.probabilities = probabilities\n",
    "\n",
    "    epsilon = 0.001\n",
    "    alpha = [[proba/(1 - min(risk_aversion)) for proba in probabilities] for i in range(community_size)]\n",
    "    #alpha = [[0.2 for proba in probabilities] for i in range(community_size)]\n",
    "    gamma = [100000 for proba in probabilities]\n",
    "\n",
    "    j_max = [10 for i in range(community_size)]\n",
    "\n",
    "    for i in range(community_size):\n",
    "        agent = StackelbergPlayer(i, d_target[i], g_res[i], a[i], b[i], d[i], \n",
    "                    A_tilde[i], B_tilde[i], D_min[i], D_max[i], \n",
    "                    G_min[i], G_max[i], risk_aversion[i], Kappa[i], Cost[i], connection_matrix[i],\n",
    "                    probabilities = probabilities,\n",
    "                    alpha = alpha[i], \n",
    "                    gamma = gamma, \n",
    "                    insurance_bound=j_max[i])\n",
    "        \n",
    "        agents.append(agent)\n",
    "\n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vars_to_dict(model, list_vars):\n",
    "    var_names = []\n",
    "    \n",
    "    for var in model.getVars():\n",
    "        var_names.append(var.VarName)\n",
    "\n",
    "    dict_res = {}\n",
    "    for name, var in zip(var_names, list_vars):\n",
    "        dict_res.update({name : var})\n",
    "\n",
    "    return dict_res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gurobi_experiment(df_param, index, err_track, connection_matrix, probabilities, d_target, g_res, solution_type, verbosity = 0):\n",
    "    A_tilde, B_tilde, a, b, d, risk_aversion = param_input(df_param, index = index)\n",
    "\n",
    "    if solution_type == 'centralized_optimistic':\n",
    "        agents = agents_list_optimistic_total(A_tilde, B_tilde, a, b, d, risk_aversion, probabilities, connection_matrix, d_target, g_res)\n",
    "\n",
    "    model_1 = gp.Model()\n",
    "    setup = GurobiSolution(agents=agents,\n",
    "                    model = model_1,\n",
    "                    solution_type=solution_type)\n",
    "\n",
    "    model_1.setParam('OutputFlag', verbosity)\n",
    "\n",
    "    setup.build_model()\n",
    "\n",
    "    try:\n",
    "        model_1.optimize()\n",
    "\n",
    "        list_vars = model_1.X\n",
    "        dict_vars = vars_to_dict(model_1, list_vars)\n",
    "        objective_val = model_1.getObjective().getValue()\n",
    "        \n",
    "        \n",
    "        \n",
    "    except:\n",
    "        err_track.append(index)\n",
    "        list_vars = ['err']\n",
    "        objective_val = 'err'\n",
    "        dict_vars = vars_to_dict(model_1, list_vars)\n",
    "\n",
    "    return dict_vars, objective_val, model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_min = [0 for i in range(community_size)]\n",
    "D_max = [dataframe_dict[i].demand.max() for i in dataframe_dict.keys()]\n",
    "\n",
    "G_min = [0 for i in range(community_size)]\n",
    "G_max = [dataframe_dict[i].grid.max() for i in dataframe_dict.keys()]\n",
    "\n",
    "Kappa = [[10 if i!=j else 0 for i in range(community_size)] for j in range(community_size)]\n",
    "\n",
    "Cost = [[1 for i in range(community_size)] for j in range(community_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_matrix_2 = text_to_adj_matrix('../matrices/matrix_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(probabilities, connection_matrix, d_target, g_res,\n",
    "                df_param, solution_type='centralized_optimistic', verbosity = 0):\n",
    "\n",
    "    total_results= {}\n",
    "    err_track = []\n",
    "    for index in tqdm_notebook(df_param.index.levels[0]):\n",
    "        vars, objective, model = gurobi_experiment(df_param, index, err_track, connection_matrix, probabilities, d_target, g_res, solution_type, verbosity)\n",
    "        total_results.update({index: {'vars' : vars,\n",
    "                                    'objective' : objective}})\n",
    "\n",
    "\n",
    "    results_vars = pd.DataFrame(data = [list(total_results[0]['vars'].values())],\n",
    "                                        columns=total_results[0]['vars'].keys())\n",
    "\n",
    "    results_vars['objective'] = total_results[0]['objective']\n",
    "\n",
    "    for i in tqdm_notebook(range(1, len(total_results))):\n",
    "        df_temp = pd.DataFrame(data = [list(total_results[i]['vars'].values())],\n",
    "                                            columns=total_results[i]['vars'].keys())\n",
    "                                \n",
    "        df_temp['objective'] = total_results[i]['objective']\n",
    "\n",
    "        results_vars = pd.concat([results_vars, df_temp], ignore_index=True)\n",
    "\n",
    "    return total_results, results_vars, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/gq_0lybs5k55th2hc4jstmyw00m7tv/T/ipykernel_13532/2132750934.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index in tqdm_notebook(df_param.index.levels[0]):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b29dd1d88744dba994eae0d5fc8310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "\n",
      "--------------------------------------------\n",
      "Warning: your license will expire in 1 days\n",
      "--------------------------------------------\n",
      "\n",
      "Academic license - for non-commercial use only - expires 2022-04-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/gq_0lybs5k55th2hc4jstmyw00m7tv/T/ipykernel_13532/2132750934.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(1, len(total_results))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f7a6056fa3413e9473d9e9bf4c1b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1999 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_opt, df_opt, model_opt = experiment(probabilities, connection_matrix_2, d_target, g_res,\n",
    "            df_param, solution_type='centralized_optimistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_0_0</th>\n",
       "      <th>D_0_1</th>\n",
       "      <th>D_0_2</th>\n",
       "      <th>D_0_3</th>\n",
       "      <th>D_0_4</th>\n",
       "      <th>D_0_5</th>\n",
       "      <th>D_0_6</th>\n",
       "      <th>D_0_7</th>\n",
       "      <th>D_0_8</th>\n",
       "      <th>D_0_9</th>\n",
       "      <th>...</th>\n",
       "      <th>u_24_91</th>\n",
       "      <th>u_24_92</th>\n",
       "      <th>u_24_93</th>\n",
       "      <th>u_24_94</th>\n",
       "      <th>u_24_95</th>\n",
       "      <th>u_24_96</th>\n",
       "      <th>u_24_97</th>\n",
       "      <th>u_24_98</th>\n",
       "      <th>u_24_99</th>\n",
       "      <th>objective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.888336e-02</td>\n",
       "      <td>8.440026e-02</td>\n",
       "      <td>1.398297e-01</td>\n",
       "      <td>1.951687e-01</td>\n",
       "      <td>2.504141e-01</td>\n",
       "      <td>3.055625e-01</td>\n",
       "      <td>3.606103e-01</td>\n",
       "      <td>0.415554</td>\n",
       "      <td>0.470394</td>\n",
       "      <td>0.529166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.941769e-08</td>\n",
       "      <td>1.465730e-08</td>\n",
       "      <td>2.163078e-08</td>\n",
       "      <td>1.458044e-08</td>\n",
       "      <td>2.187829e-08</td>\n",
       "      <td>1.302198e-08</td>\n",
       "      <td>1.986621e-08</td>\n",
       "      <td>3.033073e-08</td>\n",
       "      <td>3.086437e-08</td>\n",
       "      <td>1.395002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.004262e-09</td>\n",
       "      <td>7.463529e-09</td>\n",
       "      <td>8.139983e-09</td>\n",
       "      <td>1.975685e-08</td>\n",
       "      <td>4.512363e-08</td>\n",
       "      <td>1.244142e-07</td>\n",
       "      <td>8.740520e-07</td>\n",
       "      <td>0.036018</td>\n",
       "      <td>0.088652</td>\n",
       "      <td>0.141344</td>\n",
       "      <td>...</td>\n",
       "      <td>2.941165e-05</td>\n",
       "      <td>2.234818e-05</td>\n",
       "      <td>3.223080e-05</td>\n",
       "      <td>2.239762e-05</td>\n",
       "      <td>3.232023e-05</td>\n",
       "      <td>2.005725e-05</td>\n",
       "      <td>2.968245e-05</td>\n",
       "      <td>4.046110e-05</td>\n",
       "      <td>4.049895e-05</td>\n",
       "      <td>-0.646954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.735263e-10</td>\n",
       "      <td>1.689799e-09</td>\n",
       "      <td>4.821260e-02</td>\n",
       "      <td>1.032066e-01</td>\n",
       "      <td>1.581608e-01</td>\n",
       "      <td>2.130748e-01</td>\n",
       "      <td>2.679478e-01</td>\n",
       "      <td>0.322779</td>\n",
       "      <td>0.377569</td>\n",
       "      <td>0.432316</td>\n",
       "      <td>...</td>\n",
       "      <td>5.194807e-08</td>\n",
       "      <td>3.555443e-08</td>\n",
       "      <td>5.940394e-08</td>\n",
       "      <td>3.587835e-08</td>\n",
       "      <td>6.003435e-08</td>\n",
       "      <td>3.127193e-08</td>\n",
       "      <td>5.352265e-08</td>\n",
       "      <td>8.375391e-08</td>\n",
       "      <td>8.431324e-08</td>\n",
       "      <td>-2.573902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.580877e-09</td>\n",
       "      <td>1.493271e-08</td>\n",
       "      <td>1.613973e-08</td>\n",
       "      <td>4.093163e-08</td>\n",
       "      <td>9.542607e-08</td>\n",
       "      <td>2.737211e-07</td>\n",
       "      <td>1.171450e-06</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.069872</td>\n",
       "      <td>0.116910</td>\n",
       "      <td>...</td>\n",
       "      <td>7.249486e-08</td>\n",
       "      <td>5.171435e-08</td>\n",
       "      <td>8.062186e-08</td>\n",
       "      <td>5.167178e-08</td>\n",
       "      <td>8.059098e-08</td>\n",
       "      <td>4.526349e-08</td>\n",
       "      <td>7.238501e-08</td>\n",
       "      <td>1.045330e-07</td>\n",
       "      <td>1.045417e-07</td>\n",
       "      <td>3.278736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.014804e-02</td>\n",
       "      <td>6.541044e-02</td>\n",
       "      <td>1.205502e-01</td>\n",
       "      <td>1.755616e-01</td>\n",
       "      <td>2.304383e-01</td>\n",
       "      <td>2.851740e-01</td>\n",
       "      <td>3.443389e-01</td>\n",
       "      <td>0.406856</td>\n",
       "      <td>0.469215</td>\n",
       "      <td>0.531126</td>\n",
       "      <td>...</td>\n",
       "      <td>9.626517e-08</td>\n",
       "      <td>6.678267e-08</td>\n",
       "      <td>1.100500e-07</td>\n",
       "      <td>6.591544e-08</td>\n",
       "      <td>1.103591e-07</td>\n",
       "      <td>5.790544e-08</td>\n",
       "      <td>9.811682e-08</td>\n",
       "      <td>1.457543e-07</td>\n",
       "      <td>1.464186e-07</td>\n",
       "      <td>1.801908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2.750440e-09</td>\n",
       "      <td>1.397484e-08</td>\n",
       "      <td>7.665084e-07</td>\n",
       "      <td>5.291875e-02</td>\n",
       "      <td>1.058755e-01</td>\n",
       "      <td>1.582814e-01</td>\n",
       "      <td>2.088872e-01</td>\n",
       "      <td>0.259596</td>\n",
       "      <td>0.309830</td>\n",
       "      <td>0.359881</td>\n",
       "      <td>...</td>\n",
       "      <td>3.489625e-08</td>\n",
       "      <td>2.474662e-08</td>\n",
       "      <td>3.889585e-08</td>\n",
       "      <td>2.478637e-08</td>\n",
       "      <td>3.895433e-08</td>\n",
       "      <td>2.178734e-08</td>\n",
       "      <td>3.512584e-08</td>\n",
       "      <td>4.968284e-08</td>\n",
       "      <td>4.960223e-08</td>\n",
       "      <td>1.383177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>3.822750e-10</td>\n",
       "      <td>4.176839e-09</td>\n",
       "      <td>5.634164e-02</td>\n",
       "      <td>1.193837e-01</td>\n",
       "      <td>1.796928e-01</td>\n",
       "      <td>2.400637e-01</td>\n",
       "      <td>2.990931e-01</td>\n",
       "      <td>0.357684</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.475355</td>\n",
       "      <td>...</td>\n",
       "      <td>6.522665e-08</td>\n",
       "      <td>4.573316e-08</td>\n",
       "      <td>7.313858e-08</td>\n",
       "      <td>4.575790e-08</td>\n",
       "      <td>7.324710e-08</td>\n",
       "      <td>3.982972e-08</td>\n",
       "      <td>6.548244e-08</td>\n",
       "      <td>9.685523e-08</td>\n",
       "      <td>9.694309e-08</td>\n",
       "      <td>0.950987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3.128643e-09</td>\n",
       "      <td>2.161061e-08</td>\n",
       "      <td>5.211283e-08</td>\n",
       "      <td>2.355379e-02</td>\n",
       "      <td>8.452993e-02</td>\n",
       "      <td>1.390284e-01</td>\n",
       "      <td>1.888958e-01</td>\n",
       "      <td>0.236921</td>\n",
       "      <td>0.283690</td>\n",
       "      <td>0.335619</td>\n",
       "      <td>...</td>\n",
       "      <td>4.528101e-07</td>\n",
       "      <td>3.308169e-07</td>\n",
       "      <td>5.006603e-07</td>\n",
       "      <td>3.320344e-07</td>\n",
       "      <td>5.011005e-07</td>\n",
       "      <td>2.933692e-07</td>\n",
       "      <td>4.551631e-07</td>\n",
       "      <td>6.449526e-07</td>\n",
       "      <td>6.454057e-07</td>\n",
       "      <td>6.022974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.165589e-08</td>\n",
       "      <td>3.960997e-02</td>\n",
       "      <td>9.436816e-02</td>\n",
       "      <td>1.576349e-01</td>\n",
       "      <td>2.195919e-01</td>\n",
       "      <td>2.805873e-01</td>\n",
       "      <td>3.414853e-01</td>\n",
       "      <td>0.401699</td>\n",
       "      <td>0.461674</td>\n",
       "      <td>0.520955</td>\n",
       "      <td>...</td>\n",
       "      <td>8.870190e-07</td>\n",
       "      <td>7.029368e-07</td>\n",
       "      <td>9.524291e-07</td>\n",
       "      <td>7.001760e-07</td>\n",
       "      <td>9.663698e-07</td>\n",
       "      <td>5.953575e-07</td>\n",
       "      <td>9.209626e-07</td>\n",
       "      <td>1.158450e-06</td>\n",
       "      <td>1.167416e-06</td>\n",
       "      <td>1.473206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1.482578e-09</td>\n",
       "      <td>2.350212e-08</td>\n",
       "      <td>5.521827e-02</td>\n",
       "      <td>1.187775e-01</td>\n",
       "      <td>1.772406e-01</td>\n",
       "      <td>2.340597e-01</td>\n",
       "      <td>2.901386e-01</td>\n",
       "      <td>0.346035</td>\n",
       "      <td>0.401804</td>\n",
       "      <td>0.457630</td>\n",
       "      <td>...</td>\n",
       "      <td>4.105655e-08</td>\n",
       "      <td>3.285765e-08</td>\n",
       "      <td>4.478649e-08</td>\n",
       "      <td>3.311048e-08</td>\n",
       "      <td>4.535077e-08</td>\n",
       "      <td>3.039940e-08</td>\n",
       "      <td>4.248695e-08</td>\n",
       "      <td>5.736469e-08</td>\n",
       "      <td>5.795109e-08</td>\n",
       "      <td>-1.003218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 17326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             D_0_0         D_0_1         D_0_2         D_0_3         D_0_4  \\\n",
       "0     2.888336e-02  8.440026e-02  1.398297e-01  1.951687e-01  2.504141e-01   \n",
       "1     4.004262e-09  7.463529e-09  8.139983e-09  1.975685e-08  4.512363e-08   \n",
       "2     3.735263e-10  1.689799e-09  4.821260e-02  1.032066e-01  1.581608e-01   \n",
       "3     7.580877e-09  1.493271e-08  1.613973e-08  4.093163e-08  9.542607e-08   \n",
       "4     1.014804e-02  6.541044e-02  1.205502e-01  1.755616e-01  2.304383e-01   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1995  2.750440e-09  1.397484e-08  7.665084e-07  5.291875e-02  1.058755e-01   \n",
       "1996  3.822750e-10  4.176839e-09  5.634164e-02  1.193837e-01  1.796928e-01   \n",
       "1997  3.128643e-09  2.161061e-08  5.211283e-08  2.355379e-02  8.452993e-02   \n",
       "1998  1.165589e-08  3.960997e-02  9.436816e-02  1.576349e-01  2.195919e-01   \n",
       "1999  1.482578e-09  2.350212e-08  5.521827e-02  1.187775e-01  1.772406e-01   \n",
       "\n",
       "             D_0_5         D_0_6     D_0_7     D_0_8     D_0_9  ...  \\\n",
       "0     3.055625e-01  3.606103e-01  0.415554  0.470394  0.529166  ...   \n",
       "1     1.244142e-07  8.740520e-07  0.036018  0.088652  0.141344  ...   \n",
       "2     2.130748e-01  2.679478e-01  0.322779  0.377569  0.432316  ...   \n",
       "3     2.737211e-07  1.171450e-06  0.020100  0.069872  0.116910  ...   \n",
       "4     2.851740e-01  3.443389e-01  0.406856  0.469215  0.531126  ...   \n",
       "...            ...           ...       ...       ...       ...  ...   \n",
       "1995  1.582814e-01  2.088872e-01  0.259596  0.309830  0.359881  ...   \n",
       "1996  2.400637e-01  2.990931e-01  0.357684  0.416290  0.475355  ...   \n",
       "1997  1.390284e-01  1.888958e-01  0.236921  0.283690  0.335619  ...   \n",
       "1998  2.805873e-01  3.414853e-01  0.401699  0.461674  0.520955  ...   \n",
       "1999  2.340597e-01  2.901386e-01  0.346035  0.401804  0.457630  ...   \n",
       "\n",
       "           u_24_91       u_24_92       u_24_93       u_24_94       u_24_95  \\\n",
       "0     1.941769e-08  1.465730e-08  2.163078e-08  1.458044e-08  2.187829e-08   \n",
       "1     2.941165e-05  2.234818e-05  3.223080e-05  2.239762e-05  3.232023e-05   \n",
       "2     5.194807e-08  3.555443e-08  5.940394e-08  3.587835e-08  6.003435e-08   \n",
       "3     7.249486e-08  5.171435e-08  8.062186e-08  5.167178e-08  8.059098e-08   \n",
       "4     9.626517e-08  6.678267e-08  1.100500e-07  6.591544e-08  1.103591e-07   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1995  3.489625e-08  2.474662e-08  3.889585e-08  2.478637e-08  3.895433e-08   \n",
       "1996  6.522665e-08  4.573316e-08  7.313858e-08  4.575790e-08  7.324710e-08   \n",
       "1997  4.528101e-07  3.308169e-07  5.006603e-07  3.320344e-07  5.011005e-07   \n",
       "1998  8.870190e-07  7.029368e-07  9.524291e-07  7.001760e-07  9.663698e-07   \n",
       "1999  4.105655e-08  3.285765e-08  4.478649e-08  3.311048e-08  4.535077e-08   \n",
       "\n",
       "           u_24_96       u_24_97       u_24_98       u_24_99  objective  \n",
       "0     1.302198e-08  1.986621e-08  3.033073e-08  3.086437e-08   1.395002  \n",
       "1     2.005725e-05  2.968245e-05  4.046110e-05  4.049895e-05  -0.646954  \n",
       "2     3.127193e-08  5.352265e-08  8.375391e-08  8.431324e-08  -2.573902  \n",
       "3     4.526349e-08  7.238501e-08  1.045330e-07  1.045417e-07   3.278736  \n",
       "4     5.790544e-08  9.811682e-08  1.457543e-07  1.464186e-07   1.801908  \n",
       "...            ...           ...           ...           ...        ...  \n",
       "1995  2.178734e-08  3.512584e-08  4.968284e-08  4.960223e-08   1.383177  \n",
       "1996  3.982972e-08  6.548244e-08  9.685523e-08  9.694309e-08   0.950987  \n",
       "1997  2.933692e-07  4.551631e-07  6.449526e-07  6.454057e-07   6.022974  \n",
       "1998  5.953575e-07  9.209626e-07  1.158450e-06  1.167416e-06   1.473206  \n",
       "1999  3.039940e-08  4.248695e-08  5.736469e-08  5.795109e-08  -1.003218  \n",
       "\n",
       "[2000 rows x 17326 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt.to_csv(f'../data/optimistic_results_{len(df_opt)}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_utility_from_df_row(df_row, agents):\n",
    "    res = []\n",
    "    for agent in agents:\n",
    "        eta_idx = f'eta_{agent.id}'\n",
    "        agent_obj = df_row[eta_idx]\n",
    "\n",
    "        for proba in agent.probabilities_ind:\n",
    "            u_idx = f'u_{agent.id}_{proba}'\n",
    "            w_idx = f'W_{agent.id}_{proba}'\n",
    "            j_idx = f'J_{agent.id}_{proba}'\n",
    "\n",
    "            agent_obj += (agent.alpha[proba] * df_row[j_idx]\n",
    "                        + agent.gamma[proba] * df_row[w_idx]\n",
    "                        + agent.probabilities[proba] / (1 - agent.risk_aversion) * df_row[u_idx])\n",
    "\n",
    "        res.append(agent_obj)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IC_utility_from_df_row(df_row, agents):\n",
    "    res = 0\n",
    "\n",
    "    for agent in agents:\n",
    "        for proba in agent.probabilities_ind:\n",
    "            j_idx = f'J_{agent.id}_{proba}'\n",
    "\n",
    "            res += - agent.alpha[proba] * df_row[j_idx] + agent.probabilities[proba] * df_row[j_idx]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_objectives = []\n",
    "for index, row in df_opt.iterrows():\n",
    "    A_tilde, B_tilde, a, b, d, risk_aversion = param_input(df_param, index)\n",
    "    agents = agents_list_optimistic_total(A_tilde, B_tilde, a, b, d, risk_aversion, probabilities, connection_matrix_2, d_target, g_res)\n",
    "    agent_objectives.append(agent_utility_from_df_row(row, agents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_param = df_param.to_dict()\n",
    "for i in range(community_size):\n",
    "    for trial_idx, trial in enumerate(agent_objectives):\n",
    "        dict_df_param[f'{i}'].update({(trial_idx, 'objective') : trial[i]})\n",
    "\n",
    "df_param = pd.DataFrame(dict_df_param).sort_index(level=0)\n",
    "df_param.to_csv(f'../data/optimistic_params_{2000}_with_obj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "IC_objective = []\n",
    "for index, row in df_opt.iterrows():\n",
    "    A_tilde, B_tilde, a, b, d, risk_aversion = param_input(df_param, index)\n",
    "    agents = agents_list_optimistic_total(A_tilde, B_tilde, a, b, d, risk_aversion, probabilities, connection_matrix_2, d_target, g_res)\n",
    "    IC_objective.append(IC_utility_from_df_row(row, agents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "IC_objective = pd.Series(IC_objective, name='IC objective optimistic')\n",
    "IC_objective.to_csv('../data/IC_objective_optimistic_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2000.000000\n",
       "mean       -0.345638\n",
       "std         0.236447\n",
       "min        -1.174773\n",
       "25%        -0.502217\n",
       "50%        -0.313272\n",
       "75%        -0.151614\n",
       "max        -0.000366\n",
       "Name: IC objective optimistic, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IC_objective.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc51f7b0a90f6051b3373596df13638ac01198d8ab4bced12ffaa78c40a2d902"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
