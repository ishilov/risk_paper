{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_size = 3\n",
    "\n",
    "D_min = [0.0,0.0,0.0]\n",
    "D_max = [10.0,10.0,10.0]\n",
    "\n",
    "G_min = [0.0,0.0,0.0]\n",
    "G_max = [10.0,0.0,0.0]\n",
    "\n",
    "Kappa = [[0.0, 10.0, 10.0],\n",
    "            [10.0, 0.0, 5.0],\n",
    "            [10.0, 5.0, 0.0]]\n",
    "\n",
    "Cost = [[0.0, 1.0, 1.0],\n",
    "        [3.0, 0.0, 1.0],\n",
    "        [2.0, 1.0, 0.0]]\n",
    "\n",
    "#probabilities = [0.5, 0.5]\n",
    "\n",
    "probabilities = [1]\n",
    "connection_matrix = [[0,1,1],[1,0,1],[1,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "A_tilde = [random.uniform(0,1) for i in range(community_size)]\n",
    "B_tilde = [random.uniform(0,1) for i in range(community_size)]\n",
    "\n",
    "a = [random.uniform(0,1) for i in range(community_size)]\n",
    "b = [random.uniform(0,1) for i in range(community_size)]\n",
    "d = [random.uniform(0,1) for i in range(community_size)]\n",
    "\n",
    "d_target = [[random.uniform(0,8) for j in range(len(probabilities))] for i in range(community_size)]\n",
    "g_res = [[random.uniform(0,3) for j in range(len(probabilities))] for i in range(community_size)]\n",
    "\n",
    "g_res = np.array(g_res)\n",
    "d_target = np.array(d_target)\n",
    "\n",
    "risk_aversion = [random.uniform(0,1) for i in range(community_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplement_package.game.torch_grad import TorchPlayer, BasicFunctions\n",
    "\n",
    "agents = []\n",
    "\n",
    "TorchPlayer.community_size = community_size\n",
    "\n",
    "epsilon = 0.001\n",
    "alpha = [[proba/(1 - risk_aversion[i]) for proba in probabilities] for i in range(community_size)]\n",
    "#alpha = [[0.2 for proba in probabilities] for i in range(community_size)]\n",
    "gamma = [proba/(1 - min(risk_aversion)) for proba in probabilities]\n",
    "\n",
    "j_max = [10 for i in range(community_size)]\n",
    "\n",
    "for i in range(community_size):\n",
    "    agent = TorchPlayer(i, d_target[i], g_res[i], a[i], b[i], d[i], \n",
    "                A_tilde[i], B_tilde[i], D_min[i], D_max[i], \n",
    "                G_min[i], G_max[i], risk_aversion[i], Kappa[i], Cost[i], connection_matrix[i],\n",
    "                probabilities = probabilities,\n",
    "                alpha = alpha[i], \n",
    "                gamma = gamma, \n",
    "                insurance_bound=j_max[i])\n",
    "    \n",
    "    agents.append(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probabilities': [1],\n",
       " 'probabilities_ind': [0],\n",
       " 'alpha': [1.9300294955794348],\n",
       " 'gamma': [1.9300294955794348],\n",
       " 'j_max': 10,\n",
       " 'plot_j': [[]],\n",
       " 'plot_w': [[]],\n",
       " 'id': 0,\n",
       " 'D_target': array([5.5893064]),\n",
       " 'G_res': array([2.54064993]),\n",
       " 'a': 0.5910931265033382,\n",
       " 'b': 0.7409452936564188,\n",
       " 'd': 0.34742919898623126,\n",
       " 'a_tilde': 0.39294291983570295,\n",
       " 'b_tilde': 0.6442848059857326,\n",
       " 'D_min': 0.0,\n",
       " 'D_max': 10.0,\n",
       " 'G_min': 0.0,\n",
       " 'G_max': 10.0,\n",
       " 'risk_aversion': 0.48187320334201456,\n",
       " 'q_others': {0: [[0], [0], [0]], 1: [[0], [0], [0]], 2: [[0], [0], [0]]},\n",
       " 'w_others': {},\n",
       " 'trading_cost': [0.0, 1.0, 1.0],\n",
       " 'connections': [0, 1, 1],\n",
       " 'kappa': array([ 0., 10., 10.]),\n",
       " 'G': tensor([0.], requires_grad=True),\n",
       " 'D': tensor([0.], requires_grad=True),\n",
       " 'q': tensor([[0.],\n",
       "         [0.],\n",
       "         [0.]], requires_grad=True),\n",
       " 'plot_d': [[]],\n",
       " 'plot_g': [[]],\n",
       " 'plot_u': [[]],\n",
       " 'plot_eta': [],\n",
       " 'plot_q': [[[]], [[]], [[]]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from supplement_package.gurobi_implementation.gurobi import Gurobi\n",
    "from supplement_package.gurobi_implementation.gurobi import GurobiSolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2022-04-02\n",
      "Minimize\n",
      "<gurobi.QuadExpr: 17.633632232940755 + -4.392556751140737 D_0_0\n",
      "+ 0.7409452936564188 G_0_0 + q_0_1_0 + q_0_2_0 + -4.343222849090996 D_1_0\n",
      "+ 0.7431251256132038 G_1_0 + 3.0 q_1_0_0 + q_1_2_0 + -0.0016797256038798948 D_2_0\n",
      "+ 0.9810768743708187 G_2_0 + 2.0 q_2_0_0 + q_2_1_0 + [ 0.39294291983570295 D_0_0 ^ 2\n",
      "+ 0.2955465632516691 G_0_0 ^ 2 + 0.791927992318559 D_1_0 ^ 2\n",
      "+ 0.48953542451408044 G_1_0 ^ 2 + 0.03770995958918599 D_2_0 ^ 2\n",
      "+ 0.023558685311330152 G_2_0 ^ 2 ]>\n",
      "Subject To\n",
      "  Bilateral trading for pair (0, 1) proba 0: <gurobi.LinExpr: q_0_1_0 + q_1_0_0> = 0\n",
      "  Bilateral trading for pair (0, 2) proba 0: <gurobi.LinExpr: q_0_2_0 + q_2_0_0> = 0\n",
      "SD balance for agent 0 proba 0: <gurobi.LinExpr: D_0_0 + -1.0 G_0_0 + -1.0 q_0_1_0 +\n",
      " -1.0 q_0_2_0> = 2.54065\n",
      "  Bilateral trading for pair (1, 0) proba 0: <gurobi.LinExpr: q_0_1_0 + q_1_0_0> = 0\n",
      "  Bilateral trading for pair (1, 2) proba 0: <gurobi.LinExpr: q_1_2_0 + q_2_1_0> = 0\n",
      "SD balance for agent 1 proba 0: <gurobi.LinExpr: D_1_0 + -1.0 G_1_0 + -1.0 q_1_0_0 +\n",
      " -1.0 q_1_2_0> = 2.65901\n",
      "  Bilateral trading for pair (2, 0) proba 0: <gurobi.LinExpr: q_0_2_0 + q_2_0_0> = 0\n",
      "  Bilateral trading for pair (2, 1) proba 0: <gurobi.LinExpr: q_1_2_0 + q_2_1_0> = 0\n",
      "SD balance for agent 2 proba 0: <gurobi.LinExpr: D_2_0 + -1.0 G_2_0 + -1.0 q_2_0_0 +\n",
      " -1.0 q_2_1_0> = 0.87921\n",
      "Bounds\n",
      "  0 <= D_0_0 <= 10\n",
      "  0 <= G_0_0 <= 10\n",
      "  -10 <= q_0_1_0 <= 10\n",
      "  -10 <= q_0_2_0 <= 10\n",
      "  0 <= D_1_0 <= 10\n",
      "  G_1_0 = 0\n",
      "  -10 <= q_1_0_0 <= 10\n",
      "  -5 <= q_1_2_0 <= 5\n",
      "  0 <= D_2_0 <= 10\n",
      "  G_2_0 = 0\n",
      "  -10 <= q_2_0_0 <= 10\n",
      "  -5 <= q_2_1_0 <= 5\n"
     ]
    }
   ],
   "source": [
    "model_1 = gp.Model()\n",
    "setup = GurobiSolution(agents=agents,\n",
    "                model = model_1,\n",
    "                solution_type='initial')\n",
    "\n",
    "setup.build_model()\n",
    "\n",
    "model_1.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.0 build v9.5.0rc5 (mac64[arm])\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 9 rows, 12 columns and 24 nonzeros\n",
      "Model fingerprint: 0x7a73cdff\n",
      "Model has 6 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-03, 4e+00]\n",
      "  QObjective range [5e-02, 2e+00]\n",
      "  Bounds range     [5e+00, 1e+01]\n",
      "  RHS range        [9e-01, 3e+00]\n",
      "Presolve removed 6 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 3 rows, 7 columns, 10 nonzeros\n",
      "Presolved model has 4 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 3.000e+00\n",
      " Factor NZ  : 6.000e+00\n",
      " Factor Ops : 1.400e+01 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   1.04842057e+06 -1.11811280e+06  2.00e+03 7.84e+02  1.00e+06     0s\n",
      "   1   2.20518045e+01 -6.90848615e+04  2.00e-03 7.84e-04  4.94e+03     0s\n",
      "   2   2.18190445e+01 -1.68615895e+02  3.30e-06 1.30e-06  1.36e+01     0s\n",
      "   3   5.49092364e-03 -1.78044711e+01  3.30e-12 1.30e-12  1.27e+00     0s\n",
      "   4  -6.66156280e+00 -9.28214918e+00  1.78e-15 8.88e-16  1.87e-01     0s\n",
      "   5  -7.25279038e+00 -7.40489033e+00  2.66e-15 8.88e-16  1.09e-02     0s\n",
      "   6  -7.30771341e+00 -7.31665659e+00  1.21e-13 4.44e-16  6.39e-04     0s\n",
      "   7  -7.31506765e+00 -7.31526521e+00  8.18e-13 1.15e-16  1.41e-05     0s\n",
      "   8  -7.31525665e+00 -7.31525685e+00  2.36e-12 8.88e-16  1.45e-08     0s\n",
      "   9  -7.31525684e+00 -7.31525684e+00  2.05e-12 4.44e-16  1.45e-11     0s\n",
      "\n",
      "Barrier solved model in 9 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective -7.31525684e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "rho = 100\n",
    "\n",
    "vars = []\n",
    "with torch.no_grad():\n",
    "    for agent in agents:\n",
    "        vars += [agent.G, agent.D, agent.q]\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "optimizer = optim.SGD(vars, lr = lr, momentum=0.9, nesterov=True)\n",
    "\n",
    "for i in range(5000):\n",
    "    for agent in agents:\n",
    "        \n",
    "        utility = BasicFunctions.utility(agent) \n",
    "        penalty_SD_balance = BasicFunctions.penalty_SD_balance(agent)\n",
    "        penalty_demand_bounds_lower = BasicFunctions.penalty_demand_bounds_lower(agent)\n",
    "        penalty_demand_bounds_upper = BasicFunctions.penalty_demand_bounds_upper(agent)\n",
    "        penalty_generation_bounds_lower = BasicFunctions.penalty_generation_bounds_lower(agent)\n",
    "        penalty_generation_bounds_upper = BasicFunctions.penalty_generation_bounds_upper(agent)\n",
    "        penalty_trading_bound_lower = BasicFunctions.penalty_trading_bound_lower(agent)\n",
    "        penalty_trading_bound_upper = BasicFunctions.penalty_trading_bound_upper(agent)\n",
    "        penalty_bilateral_trading_bounds = BasicFunctions.penalty_bilateral_trading_bounds(agent)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for proba in agent.probabilities_ind:\n",
    "            loss += (utility[proba]\n",
    "                + rho * penalty_SD_balance[proba]\n",
    "                + rho * penalty_demand_bounds_lower[proba]\n",
    "                + rho * penalty_demand_bounds_upper[proba]\n",
    "                + rho * penalty_generation_bounds_lower[proba]\n",
    "                + rho * penalty_generation_bounds_upper[proba])\n",
    "\n",
    "            for agent_2, connection in enumerate(agent.connections):\n",
    "                if connection:\n",
    "                    loss += (rho * penalty_trading_bound_lower[agent_2][proba]\n",
    "                            + rho * penalty_trading_bound_upper[agent_2][proba]\n",
    "                            + rho * penalty_bilateral_trading_bounds[agent_2][proba])\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        for proba in agent.probabilities_ind:\n",
    "            with torch.no_grad():\n",
    "                agent.plot_d[proba].append(agent.D.data.numpy()[proba])\n",
    "                agent.plot_g[proba].append(agent.G.data.numpy()[proba])\n",
    "                \n",
    "                for agent_2 in agents:\n",
    "                    agent.plot_q[agent_2.id][proba].append(agent.q.data.numpy()[agent_2.id][proba])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        for agent_2 in agents:\n",
    "            for proba in agent.probabilities_ind:\n",
    "                agent_2.q_others[agent.id] = agent.q.data.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(52.9799, dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost = 0\n",
    "with torch.no_grad():\n",
    "    for agent in agents:\n",
    "        total_cost += sum(BasicFunctions.utility(agent))\n",
    "\n",
    "total_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.315256843836345"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.ObjVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<gurobi.Var D_0_0 (value 4.927703735620974)>,\n",
       " <gurobi.Var G_0_0 (value 8.790462277225568e-10)>,\n",
       " <gurobi.Var q_0_1_0 (value 6.507843821820517)>,\n",
       " <gurobi.Var q_0_2_0 (value -4.12079002112349)>,\n",
       " <gurobi.Var D_1_0 (value 1.1511644389116749)>,\n",
       " <gurobi.Var G_1_0 (value 0.0)>,\n",
       " <gurobi.Var q_1_0_0 (value -6.507843821820517)>,\n",
       " <gurobi.Var q_1_2_0 (value 4.999999999999312)>,\n",
       " <gurobi.Var D_2_0 (value 4.3448943719030424e-13)>,\n",
       " <gurobi.Var G_2_0 (value 0.0)>,\n",
       " <gurobi.Var q_2_0_0 (value 4.12079002112349)>,\n",
       " <gurobi.Var q_2_1_0 (value -4.999999999999312)>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.getVars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [tensor([10.4654], requires_grad=True),\n",
       "   tensor([-0.4762], requires_grad=True),\n",
       "   tensor([[0.0000],\n",
       "           [5.1995],\n",
       "           [2.7357]], requires_grad=True),\n",
       "   tensor([0.4939], requires_grad=True),\n",
       "   tensor([-0.4745], requires_grad=True),\n",
       "   tensor([[-4.7098],\n",
       "           [ 0.0000],\n",
       "           [ 0.2719]], requires_grad=True),\n",
       "   tensor([0.4950], requires_grad=True),\n",
       "   tensor([-0.4998], requires_grad=True),\n",
       "   tensor([[-2.2432],\n",
       "           [ 0.2231],\n",
       "           [ 0.0000]], requires_grad=True)],\n",
       "  'lr': 0.0001,\n",
       "  'momentum': 0.9,\n",
       "  'dampening': 0,\n",
       "  'weight_decay': 0,\n",
       "  'nesterov': True}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for agent in agents:\n",
    "    for proba in agent.probabilities_ind:\n",
    "        plt.plot(agent.plot_g[proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tilde = [1, 2, 3]\n",
    "B_tilde = [4, ]\n",
    "\n",
    "a = [1, 1, 1]\n",
    "b = [-3, -4, -1]\n",
    "d = [2, 4, 1]\n",
    "\n",
    "d_target = [1, 2, 3]\n",
    "g_res = [2, 3, 4]\n",
    "\n",
    "g_res = np.array(g_res)\n",
    "d_target = np.array(d_target)\n",
    "\n",
    "risk_aversion = [random.uniform(0,1) for i in range(community_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = []\n",
    "\n",
    "TorchPlayer.community_size = community_size\n",
    "\n",
    "epsilon = 0.001\n",
    "alpha = [[proba/(1 - risk_aversion[i]) for proba in probabilities] for i in range(community_size)]\n",
    "#alpha = [[0.2 for proba in probabilities] for i in range(community_size)]\n",
    "gamma = [proba/(1 - min(risk_aversion)) for proba in probabilities]\n",
    "\n",
    "j_max = [10 for i in range(community_size)]\n",
    "\n",
    "for i in range(community_size):\n",
    "    agent = TorchPlayer(i, d_target[i], g_res[i], a[i], b[i], d[i], \n",
    "                A_tilde[i], B_tilde[i], D_min[i], D_max[i], \n",
    "                G_min[i], G_max[i], risk_aversion[i], Kappa[i], Cost[i], connection_matrix[i],\n",
    "                probabilities = probabilities,\n",
    "                alpha = alpha[i], \n",
    "                gamma = gamma, \n",
    "                insurance_bound=j_max[i])\n",
    "    \n",
    "    agents.append(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimize\n",
      "<gurobi.QuadExpr: 16.877046801663617 + -49.66319581494169 G_0_0 +\n",
      "-62.78106620928543 G_1_0 + -15.718121826181475 G_2_0 + [ 0.6592947665005213 G_0_0 ^ 2\n",
      "+ 0.03376708334737849 G_1_0 ^ 2 + 1.1421542561315494 G_2_0 ^ 2 ]>\n",
      "Subject To\n",
      "Bounds\n",
      "  0 <= G_0_0 <= 10\n",
      "  G_1_0 = 0\n",
      "  G_2_0 = 0\n"
     ]
    }
   ],
   "source": [
    "model_2 = gp.Model()\n",
    "setup = GurobiSolution(agents=agents,\n",
    "                model = model_2,\n",
    "                solution_type='test')\n",
    "\n",
    "setup.build_model()\n",
    "\n",
    "model_2.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.0 build v9.5.0rc5 (mac64[arm])\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 0 rows, 3 columns and 0 nonzeros\n",
      "Model fingerprint: 0x173f533d\n",
      "Model has 3 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [0e+00, 0e+00]\n",
      "  Objective range  [2e+01, 6e+01]\n",
      "  QObjective range [7e-02, 2e+00]\n",
      "  Bounds range     [1e+01, 1e+01]\n",
      "  RHS range        [0e+00, 0e+00]\n",
      "Presolve removed 0 rows and 3 columns\n",
      "Presolve time: 0.01s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Barrier solved model in 0 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective -4.13825435e+02\n"
     ]
    }
   ],
   "source": [
    "model_2.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<gurobi.Var G_0_0 (value 10.0)>,\n",
       " <gurobi.Var G_1_0 (value 0.0)>,\n",
       " <gurobi.Var G_2_0 (value 0.0)>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.getVars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "rho = 10000\n",
    "\n",
    "vars = []\n",
    "with torch.no_grad():\n",
    "    for agent in agents:\n",
    "        vars += [agent.G]\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "optimizer = optim.SGD(vars, lr = lr, momentum=0.9, nesterov=True)\n",
    "\n",
    "for i in range(10000):\n",
    "    for agent in agents:\n",
    "        \n",
    "        utility = BasicFunctions.utility_generation(agent) \n",
    "        penalty_generation_bounds_lower = BasicFunctions.penalty_generation_bounds_lower(agent)\n",
    "        penalty_generation_bounds_upper = BasicFunctions.penalty_generation_bounds_upper(agent)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for proba in agent.probabilities_ind:\n",
    "            loss += (utility[proba]\n",
    "                + rho * penalty_generation_bounds_lower[proba]\n",
    "                + rho * penalty_generation_bounds_upper[proba])\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        for proba in agent.probabilities_ind:\n",
    "            with torch.no_grad():\n",
    "                agent.plot_g[proba].append(agent.G.data.numpy()[proba])\n",
    "                \n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.0018], requires_grad=True)\n",
      "tensor([0.0031], requires_grad=True)\n",
      "tensor([0.0008], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for agent in agents:\n",
    "    print(agent.G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
