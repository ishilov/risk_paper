{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "from math import sqrt\n",
    "import scipy.stats as sts\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from supplement_package import game\n",
    "from supplement_package import variables_pecan\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplement_package.game.stackelberg import StackelbergPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "\n",
    "from supplement_package.gurobi_implementation.gurobi import GurobiSolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preliminaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_keys = [661, 1642, 2335, 2361, 2818, 3039, 3456, 3538, 4031, 4373, 4767, 5746, 6139, 7536, 7719, 7800, 7901, 7951, 8156, 8386, 8565, 9019, 9160, 9922, 9278]\n",
    "\n",
    "dataframe_dict = dict()\n",
    "for key in agent_keys:\n",
    "    dataframe_dict.update({key : pd.read_csv('/Users/ishilov/Documents/risk_paper/risk_paper/data/df_{}.csv'.format(key))})\n",
    "\n",
    "community_size = len(dataframe_dict)\n",
    "\n",
    "for key in agent_keys:\n",
    "    cond_min = (dataframe_dict[key]['demand'].quantile(0.001) <= dataframe_dict[key]['demand'])\n",
    "    cond_max = (dataframe_dict[key]['demand'] <= dataframe_dict[key]['demand'].quantile(0.999))\n",
    "    dataframe_dict[key] = dataframe_dict[key][cond_min & cond_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_params(sample_size, community_size):\n",
    "    res = {}\n",
    "\n",
    "    for sample in range(sample_size):\n",
    "        A_tilde = [random.uniform(0,1) for i in range(community_size)]\n",
    "        B_tilde = [random.uniform(0,1) for i in range(community_size)]\n",
    "\n",
    "        a = [random.uniform(0,1) for i in range(community_size)]\n",
    "        b = [random.uniform(0,1) for i in range(community_size)]\n",
    "        d = [random.uniform(0,1) for i in range(community_size)]\n",
    "\n",
    "        #d_target = [[random.uniform(0,8) for j in range(len(probabilities))] for i in range(community_size)]\n",
    "        #g_res = [[random.uniform(0,3) for j in range(len(probabilities))] for i in range(community_size)]\n",
    "\n",
    "        #g_res = np.array(g_res)\n",
    "        #d_target = np.array(d_target)\n",
    "\n",
    "        risk_aversion = [random.uniform(0,1) for i in range(community_size)]\n",
    "\n",
    "        res.update({sample : {'A_tilde' : A_tilde,\n",
    "                        'B_tilde' : B_tilde,\n",
    "                        'a' : a,\n",
    "                        'b' : b,\n",
    "                        'd' : d,\n",
    "                        'risk_aversion' : risk_aversion}})\n",
    "\n",
    "    res_reformed = {(i, key) : res[i][key] for i in range(sample_size) for key in res[0].keys()}\n",
    "    mindx = pd.MultiIndex.from_tuples(res_reformed.keys())\n",
    "    df = pd.DataFrame(list(res_reformed.values()), index = mindx)\n",
    "    df.to_csv(f'../data/param_{sample_size}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_adj_matrix(matrix_path):\n",
    "    res = []\n",
    "    with open(matrix_path) as file:\n",
    "        for s in file:\n",
    "            string = ''.join(s.strip().strip(',').split(', '))\n",
    "            lst_temp = [int(sym) for sym in string]\n",
    "\n",
    "            res.append(lst_temp)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_new_params(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df_param(sample_size):\n",
    "    df_param = pd.read_csv(f'../data/param_{sample_size}.csv')\n",
    "    df_param.rename({'Unnamed: 0' : 'Sample', 'Unnamed: 1' : 'Parameter'}, axis=1, inplace= True)\n",
    "    df_param.set_index(['Sample', 'Parameter'], inplace=True)\n",
    "\n",
    "    return df_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_build(sample_size, agent_keys):\n",
    "    res = {}\n",
    "    \n",
    "    for key in agent_keys:\n",
    "        #chunks_demand = int(demand_dict[key][0].size / sample_size)\n",
    "        #chunks_generation = int(solar_dict[key][0].size / sample_size)\n",
    "\n",
    "\n",
    "        #probas_demand = [np.trapz(demand_dict[key][1][i * sample_size : (i + 1) * sample_size],\n",
    "        #                            demand_dict[key][0][i * sample_size : (i + 1) * sample_size])\n",
    "        #                            for i in range(chunks_demand)]\n",
    "\n",
    "        #probas_generation = [np.trapz(generation_dict[key][1][i * sample_size : (i + 1) * sample_size],\n",
    "        #                            generation_dict[key][0][i * sample_size : (i + 1) * sample_size])\n",
    "        #                            for i in range(chunks_generation)]\n",
    "\n",
    "        #res_demand = plt.hist(np.random.choice(demand_dict[key][0], size = sample_size, p = probabilities), bins = int(sample_size / 2))\n",
    "        #probas_update = res_demand[0] / res_demand[0].sum() if key == 661 else res[661]['probabilities']\n",
    "        #res.update({key : \n",
    "        #            {'values' : res_demand[1], \n",
    "        #            'probabilities' : probas_update}})\n",
    "\n",
    "        hist_demand = plt.hist(dataframe_dict[key]['demand'], bins = sample_size)\n",
    "        probas_demand, values_demand = hist_demand[0], hist_demand[1]\n",
    "        probas_demand = probas_demand / probas_demand.sum()\n",
    "\n",
    "        if 'solar' in dataframe_dict[key].columns:\n",
    "            hist_solar = plt.hist(dataframe_dict[key][dataframe_dict[key]['solar'] >= 0]['solar'], bins = sample_size)\n",
    "            probas_solar , values_solar  = hist_solar[0], hist_solar[1]\n",
    "            probas_solar = probas_demand / probas_demand.sum()\n",
    "\n",
    "        res.update({key : \n",
    "                    {'probas_demand' : probas_demand,\n",
    "                    'values_demand' : values_demand,\n",
    "                    'probas_solar' : probas_solar,\n",
    "                    'values_solar' : values_solar}})\n",
    "\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_sampling(sample_size, agent_keys, main_key = 661):\n",
    "    distribution = distribution_build(sample_size, agent_keys)\n",
    "\n",
    "    probabilities = distribution[main_key]['probas_demand']\n",
    "\n",
    "    d_target = []\n",
    "    g_res = []\n",
    "    for key in agent_keys:\n",
    "        d_target.append(distribution[key]['values_demand'][:-1])\n",
    "        g_res.append(distribution[key]['values_solar'][:-1])\n",
    "\n",
    "    return probabilities, d_target, g_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_input(df, index = 0):\n",
    "    A_tilde = list(df.loc[index].loc['A_tilde'])\n",
    "    B_tilde = list(df.loc[index].loc['B_tilde'])\n",
    "    a = list(df.loc[index].loc['a'])\n",
    "    b = list(df.loc[index].loc['b'])\n",
    "    d = list(df.loc[index].loc['d'])\n",
    "    risk_aversion = list(df.loc[index].loc['risk_aversion'])\n",
    "\n",
    "    return A_tilde, B_tilde, a, b, d, risk_aversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_amount = 2000\n",
    "\n",
    "#generate_new_params(param_amount,community_size=community_size)\n",
    "df_param = read_df_param(param_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_to_csv(scenario_amount, probabilities, d_target, g_res):\n",
    "    pd.DataFrame(d_target).to_csv(f'../data/df_d_target_{scenario_amount}.csv')\n",
    "    pd.DataFrame(g_res).to_csv(f'../data/df_g_res_{scenario_amount}.csv')\n",
    "    pd.DataFrame(probabilities).to_csv(f'../data/df_probabilities_{scenario_amount}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_csv(scenario_amount):\n",
    "    df_d_target = pd.read_csv(f'../data/df_d_target_{scenario_amount}.csv').drop('Unnamed: 0', axis = 1)\n",
    "    df_g_res = pd.read_csv(f'../data/df_g_res_{scenario_amount}.csv').drop('Unnamed: 0', axis = 1)\n",
    "    df_probabilities =pd.read_csv('../data/df_probabilities_100.csv').drop('Unnamed: 0', axis = 1)\n",
    "    \n",
    "    probabilities = df_probabilities.values.squeeze()\n",
    "\n",
    "\n",
    "    d_target = []\n",
    "    for _, row in df_d_target.iterrows():\n",
    "        d_target.append(row.values)\n",
    "\n",
    "    g_res = []\n",
    "    for _, row in df_g_res.iterrows():\n",
    "        g_res.append(row.values)\n",
    "\n",
    "    return probabilities, d_target, g_res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities, d_target, g_res = sample_from_csv(100)\n",
    "A_tilde, B_tilde, a, b, d, risk_aversion = param_input(df_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agents_list_optimistic_total(A_tilde, B_tilde, a, b, d, risk_aversion, probabilities, connection_matrix, d_target, g_res):\n",
    "    agents = []\n",
    "    StackelbergPlayer.community_size = community_size\n",
    "    StackelbergPlayer.probabilities = probabilities\n",
    "\n",
    "    epsilon = 0.001\n",
    "    alpha = [[proba/(1 - min(risk_aversion)) for proba in probabilities] for i in range(community_size)]\n",
    "    #alpha = [[0.2 for proba in probabilities] for i in range(community_size)]\n",
    "    gamma = [proba/(1 - min(risk_aversion))for proba in probabilities]\n",
    "\n",
    "    j_max = [10 for i in range(community_size)]\n",
    "\n",
    "    for i in range(community_size):\n",
    "        agent = StackelbergPlayer(i, d_target[i], g_res[i], a[i], b[i], d[i], \n",
    "                    A_tilde[i], B_tilde[i], D_min[i], D_max[i], \n",
    "                    G_min[i], G_max[i], risk_aversion[i], Kappa[i], Cost[i], connection_matrix[i],\n",
    "                    probabilities = probabilities,\n",
    "                    alpha = alpha[i], \n",
    "                    gamma = gamma, \n",
    "                    insurance_bound=j_max[i])\n",
    "        \n",
    "        agents.append(agent)\n",
    "\n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vars_to_dict(model, list_vars):\n",
    "    var_names = []\n",
    "    \n",
    "    for var in model.getVars():\n",
    "        var_names.append(var.VarName)\n",
    "\n",
    "    dict_res = {}\n",
    "    for name, var in zip(var_names, list_vars):\n",
    "        dict_res.update({name : var})\n",
    "\n",
    "    return dict_res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gurobi_experiment(df_param, index, err_track, connection_matrix, probabilities, d_target, g_res, solution_type, verbosity = 0):\n",
    "    A_tilde, B_tilde, a, b, d, risk_aversion = param_input(df_param, index = index)\n",
    "\n",
    "    if solution_type == 'without_IC':\n",
    "        agents = agents_list_optimistic_total(A_tilde, B_tilde, a, b, d, risk_aversion, probabilities, connection_matrix, d_target, g_res)\n",
    "\n",
    "    model_1 = gp.Model()\n",
    "    setup = GurobiSolution(agents=agents,\n",
    "                    model = model_1,\n",
    "                    solution_type=solution_type)\n",
    "\n",
    "    model_1.setParam('OutputFlag', verbosity)\n",
    "\n",
    "    setup.build_model()\n",
    "\n",
    "    try:\n",
    "        model_1.optimize()\n",
    "\n",
    "        list_vars = model_1.X\n",
    "        dict_vars = vars_to_dict(model_1, list_vars)\n",
    "        objective_val = model_1.getObjective().getValue()\n",
    "        \n",
    "        \n",
    "        \n",
    "    except:\n",
    "        err_track.append(index)\n",
    "        list_vars = ['err']\n",
    "        objective_val = 'err'\n",
    "        dict_vars = vars_to_dict(model_1, list_vars)\n",
    "\n",
    "    return dict_vars, objective_val, model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_min = [0 for i in range(community_size)]\n",
    "D_max = [dataframe_dict[i].demand.max() for i in dataframe_dict.keys()]\n",
    "\n",
    "G_min = [0 for i in range(community_size)]\n",
    "G_max = [dataframe_dict[i].grid.max() for i in dataframe_dict.keys()]\n",
    "\n",
    "Kappa = [[10 if i!=j else 0 for i in range(community_size)] for j in range(community_size)]\n",
    "\n",
    "Cost = [[1 for i in range(community_size)] for j in range(community_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_matrix_2 = text_to_adj_matrix('../matrices/matrix_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(A_tilde, B_tilde, a, b, d, risk_aversion, probabilities, connection_matrix, d_target, g_res,\n",
    "                df_param, solution_type='without_IC', verbosity = 0):\n",
    "\n",
    "    total_results= {}\n",
    "    err_track = []\n",
    "    for index in tqdm_notebook(df_param.index.levels[0]):\n",
    "        vars, objective, model = gurobi_experiment(df_param, index, err_track, connection_matrix, probabilities, d_target, g_res, solution_type, verbosity)\n",
    "        total_results.update({index: {'vars' : vars,\n",
    "                                    'objective' : objective}})\n",
    "\n",
    "\n",
    "    results_vars = pd.DataFrame(data = [list(total_results[0]['vars'].values())],\n",
    "                                        columns=total_results[0]['vars'].keys())\n",
    "\n",
    "    results_vars['objective'] = total_results[0]['objective']\n",
    "\n",
    "    for i in tqdm_notebook(range(1, len(total_results))):\n",
    "        df_temp = pd.DataFrame(data = [list(total_results[i]['vars'].values())],\n",
    "                                            columns=total_results[i]['vars'].keys())\n",
    "                                \n",
    "        df_temp['objective'] = total_results[i]['objective']\n",
    "\n",
    "        results_vars = pd.concat([results_vars, df_temp], ignore_index=True)\n",
    "\n",
    "    return total_results, results_vars, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/gq_0lybs5k55th2hc4jstmyw00m7tv/T/ipykernel_36399/3882877339.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index in tqdm_notebook(df_param.index.levels[0]):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a1d0b0f4514f54b044479427f70218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "\n",
      "--------------------------------------------\n",
      "Warning: your license will expire in 5 days\n",
      "--------------------------------------------\n",
      "\n",
      "Academic license - for non-commercial use only - expires 2022-04-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/gq_0lybs5k55th2hc4jstmyw00m7tv/T/ipykernel_36399/3882877339.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(1, len(total_results))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e27cfed3a040ba92119b4a2acc67d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1999 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_without_IC, df_without_IC, model_without_IC = experiment(A_tilde, B_tilde, a, b, d, risk_aversion, probabilities, connection_matrix_2, d_target, g_res,\n",
    "            df_param, solution_type='without_IC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_0_0</th>\n",
       "      <th>D_0_1</th>\n",
       "      <th>D_0_2</th>\n",
       "      <th>D_0_3</th>\n",
       "      <th>D_0_4</th>\n",
       "      <th>D_0_5</th>\n",
       "      <th>D_0_6</th>\n",
       "      <th>D_0_7</th>\n",
       "      <th>D_0_8</th>\n",
       "      <th>D_0_9</th>\n",
       "      <th>...</th>\n",
       "      <th>u_24_91</th>\n",
       "      <th>u_24_92</th>\n",
       "      <th>u_24_93</th>\n",
       "      <th>u_24_94</th>\n",
       "      <th>u_24_95</th>\n",
       "      <th>u_24_96</th>\n",
       "      <th>u_24_97</th>\n",
       "      <th>u_24_98</th>\n",
       "      <th>u_24_99</th>\n",
       "      <th>objective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.734070</td>\n",
       "      <td>2.749192</td>\n",
       "      <td>2.764204</td>\n",
       "      <td>2.779123</td>\n",
       "      <td>2.793966</td>\n",
       "      <td>2.808727</td>\n",
       "      <td>2.823447</td>\n",
       "      <td>2.838147</td>\n",
       "      <td>2.852847</td>\n",
       "      <td>2.867570</td>\n",
       "      <td>...</td>\n",
       "      <td>73.825819</td>\n",
       "      <td>74.047618</td>\n",
       "      <td>74.269049</td>\n",
       "      <td>74.534429</td>\n",
       "      <td>74.800226</td>\n",
       "      <td>75.060014</td>\n",
       "      <td>75.312898</td>\n",
       "      <td>75.566299</td>\n",
       "      <td>75.810472</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.161151</td>\n",
       "      <td>3.187446</td>\n",
       "      <td>3.213755</td>\n",
       "      <td>3.240016</td>\n",
       "      <td>3.266278</td>\n",
       "      <td>3.292518</td>\n",
       "      <td>3.318839</td>\n",
       "      <td>3.345183</td>\n",
       "      <td>3.371504</td>\n",
       "      <td>3.397591</td>\n",
       "      <td>...</td>\n",
       "      <td>94.170966</td>\n",
       "      <td>93.156756</td>\n",
       "      <td>93.474046</td>\n",
       "      <td>93.776198</td>\n",
       "      <td>94.153497</td>\n",
       "      <td>94.545998</td>\n",
       "      <td>94.945545</td>\n",
       "      <td>95.345746</td>\n",
       "      <td>95.753251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.145341</td>\n",
       "      <td>3.161979</td>\n",
       "      <td>3.178635</td>\n",
       "      <td>3.195315</td>\n",
       "      <td>3.212023</td>\n",
       "      <td>3.228761</td>\n",
       "      <td>3.245536</td>\n",
       "      <td>3.262350</td>\n",
       "      <td>3.279212</td>\n",
       "      <td>3.296120</td>\n",
       "      <td>...</td>\n",
       "      <td>86.046270</td>\n",
       "      <td>86.240560</td>\n",
       "      <td>86.440000</td>\n",
       "      <td>86.646369</td>\n",
       "      <td>83.106481</td>\n",
       "      <td>83.366756</td>\n",
       "      <td>83.633795</td>\n",
       "      <td>82.791268</td>\n",
       "      <td>83.068112</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.347357</td>\n",
       "      <td>3.372097</td>\n",
       "      <td>3.396927</td>\n",
       "      <td>3.421790</td>\n",
       "      <td>3.446693</td>\n",
       "      <td>3.471643</td>\n",
       "      <td>3.496636</td>\n",
       "      <td>3.521693</td>\n",
       "      <td>3.546824</td>\n",
       "      <td>3.572030</td>\n",
       "      <td>...</td>\n",
       "      <td>103.026267</td>\n",
       "      <td>103.239993</td>\n",
       "      <td>103.474162</td>\n",
       "      <td>103.715398</td>\n",
       "      <td>102.784379</td>\n",
       "      <td>103.033742</td>\n",
       "      <td>102.091035</td>\n",
       "      <td>102.346663</td>\n",
       "      <td>99.485502</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.875456</td>\n",
       "      <td>2.886972</td>\n",
       "      <td>2.898502</td>\n",
       "      <td>2.910011</td>\n",
       "      <td>2.921560</td>\n",
       "      <td>2.934053</td>\n",
       "      <td>2.947758</td>\n",
       "      <td>2.961552</td>\n",
       "      <td>2.975403</td>\n",
       "      <td>2.989360</td>\n",
       "      <td>...</td>\n",
       "      <td>48.453035</td>\n",
       "      <td>48.464557</td>\n",
       "      <td>47.830663</td>\n",
       "      <td>47.843479</td>\n",
       "      <td>47.856384</td>\n",
       "      <td>47.869371</td>\n",
       "      <td>47.882213</td>\n",
       "      <td>47.625633</td>\n",
       "      <td>47.637952</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>3.092264</td>\n",
       "      <td>3.106580</td>\n",
       "      <td>3.120918</td>\n",
       "      <td>3.135287</td>\n",
       "      <td>3.149695</td>\n",
       "      <td>3.164153</td>\n",
       "      <td>3.178659</td>\n",
       "      <td>3.193233</td>\n",
       "      <td>3.207887</td>\n",
       "      <td>3.222631</td>\n",
       "      <td>...</td>\n",
       "      <td>103.927701</td>\n",
       "      <td>102.824424</td>\n",
       "      <td>103.157369</td>\n",
       "      <td>103.513375</td>\n",
       "      <td>103.883579</td>\n",
       "      <td>102.452110</td>\n",
       "      <td>102.840850</td>\n",
       "      <td>103.238654</td>\n",
       "      <td>103.637944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2.976509</td>\n",
       "      <td>2.988560</td>\n",
       "      <td>3.001866</td>\n",
       "      <td>3.015891</td>\n",
       "      <td>3.029884</td>\n",
       "      <td>3.043882</td>\n",
       "      <td>3.057943</td>\n",
       "      <td>3.072114</td>\n",
       "      <td>3.086421</td>\n",
       "      <td>3.100912</td>\n",
       "      <td>...</td>\n",
       "      <td>101.888780</td>\n",
       "      <td>102.352745</td>\n",
       "      <td>102.823778</td>\n",
       "      <td>101.844977</td>\n",
       "      <td>102.312318</td>\n",
       "      <td>102.779559</td>\n",
       "      <td>103.247231</td>\n",
       "      <td>103.713734</td>\n",
       "      <td>104.178706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3.086795</td>\n",
       "      <td>3.105853</td>\n",
       "      <td>3.124933</td>\n",
       "      <td>3.143993</td>\n",
       "      <td>3.163072</td>\n",
       "      <td>3.182170</td>\n",
       "      <td>3.201293</td>\n",
       "      <td>3.220441</td>\n",
       "      <td>3.239626</td>\n",
       "      <td>3.258849</td>\n",
       "      <td>...</td>\n",
       "      <td>100.424805</td>\n",
       "      <td>100.552523</td>\n",
       "      <td>100.683945</td>\n",
       "      <td>100.819283</td>\n",
       "      <td>100.955679</td>\n",
       "      <td>101.075411</td>\n",
       "      <td>99.821148</td>\n",
       "      <td>99.960292</td>\n",
       "      <td>100.123248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2.770147</td>\n",
       "      <td>2.782242</td>\n",
       "      <td>2.794246</td>\n",
       "      <td>2.806188</td>\n",
       "      <td>2.818098</td>\n",
       "      <td>2.830010</td>\n",
       "      <td>2.841925</td>\n",
       "      <td>2.853712</td>\n",
       "      <td>2.865447</td>\n",
       "      <td>2.877305</td>\n",
       "      <td>...</td>\n",
       "      <td>89.527454</td>\n",
       "      <td>89.756532</td>\n",
       "      <td>89.988362</td>\n",
       "      <td>90.222214</td>\n",
       "      <td>90.458025</td>\n",
       "      <td>90.694441</td>\n",
       "      <td>86.675669</td>\n",
       "      <td>86.908484</td>\n",
       "      <td>87.135325</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2.921402</td>\n",
       "      <td>2.935914</td>\n",
       "      <td>2.950398</td>\n",
       "      <td>2.964875</td>\n",
       "      <td>2.979369</td>\n",
       "      <td>2.993945</td>\n",
       "      <td>3.008499</td>\n",
       "      <td>3.023018</td>\n",
       "      <td>3.037549</td>\n",
       "      <td>3.052224</td>\n",
       "      <td>...</td>\n",
       "      <td>81.408388</td>\n",
       "      <td>81.783790</td>\n",
       "      <td>82.171155</td>\n",
       "      <td>82.567511</td>\n",
       "      <td>82.970498</td>\n",
       "      <td>82.344480</td>\n",
       "      <td>82.758988</td>\n",
       "      <td>83.178507</td>\n",
       "      <td>83.596951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 17326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         D_0_0     D_0_1     D_0_2     D_0_3     D_0_4     D_0_5     D_0_6  \\\n",
       "0     2.734070  2.749192  2.764204  2.779123  2.793966  2.808727  2.823447   \n",
       "1     3.161151  3.187446  3.213755  3.240016  3.266278  3.292518  3.318839   \n",
       "2     3.145341  3.161979  3.178635  3.195315  3.212023  3.228761  3.245536   \n",
       "3     3.347357  3.372097  3.396927  3.421790  3.446693  3.471643  3.496636   \n",
       "4     2.875456  2.886972  2.898502  2.910011  2.921560  2.934053  2.947758   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  3.092264  3.106580  3.120918  3.135287  3.149695  3.164153  3.178659   \n",
       "1996  2.976509  2.988560  3.001866  3.015891  3.029884  3.043882  3.057943   \n",
       "1997  3.086795  3.105853  3.124933  3.143993  3.163072  3.182170  3.201293   \n",
       "1998  2.770147  2.782242  2.794246  2.806188  2.818098  2.830010  2.841925   \n",
       "1999  2.921402  2.935914  2.950398  2.964875  2.979369  2.993945  3.008499   \n",
       "\n",
       "         D_0_7     D_0_8     D_0_9  ...     u_24_91     u_24_92     u_24_93  \\\n",
       "0     2.838147  2.852847  2.867570  ...   73.825819   74.047618   74.269049   \n",
       "1     3.345183  3.371504  3.397591  ...   94.170966   93.156756   93.474046   \n",
       "2     3.262350  3.279212  3.296120  ...   86.046270   86.240560   86.440000   \n",
       "3     3.521693  3.546824  3.572030  ...  103.026267  103.239993  103.474162   \n",
       "4     2.961552  2.975403  2.989360  ...   48.453035   48.464557   47.830663   \n",
       "...        ...       ...       ...  ...         ...         ...         ...   \n",
       "1995  3.193233  3.207887  3.222631  ...  103.927701  102.824424  103.157369   \n",
       "1996  3.072114  3.086421  3.100912  ...  101.888780  102.352745  102.823778   \n",
       "1997  3.220441  3.239626  3.258849  ...  100.424805  100.552523  100.683945   \n",
       "1998  2.853712  2.865447  2.877305  ...   89.527454   89.756532   89.988362   \n",
       "1999  3.023018  3.037549  3.052224  ...   81.408388   81.783790   82.171155   \n",
       "\n",
       "         u_24_94     u_24_95     u_24_96     u_24_97     u_24_98     u_24_99  \\\n",
       "0      74.534429   74.800226   75.060014   75.312898   75.566299   75.810472   \n",
       "1      93.776198   94.153497   94.545998   94.945545   95.345746   95.753251   \n",
       "2      86.646369   83.106481   83.366756   83.633795   82.791268   83.068112   \n",
       "3     103.715398  102.784379  103.033742  102.091035  102.346663   99.485502   \n",
       "4      47.843479   47.856384   47.869371   47.882213   47.625633   47.637952   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1995  103.513375  103.883579  102.452110  102.840850  103.238654  103.637944   \n",
       "1996  101.844977  102.312318  102.779559  103.247231  103.713734  104.178706   \n",
       "1997  100.819283  100.955679  101.075411   99.821148   99.960292  100.123248   \n",
       "1998   90.222214   90.458025   90.694441   86.675669   86.908484   87.135325   \n",
       "1999   82.567511   82.970498   82.344480   82.758988   83.178507   83.596951   \n",
       "\n",
       "      objective  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "...         ...  \n",
       "1995        0.0  \n",
       "1996        0.0  \n",
       "1997        0.0  \n",
       "1998        0.0  \n",
       "1999        0.0  \n",
       "\n",
       "[2000 rows x 17326 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_IC.to_csv(f'../data/without_IC_results_{len(df_without_IC)}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_utility_from_df_row(df_row, agents):\n",
    "    res = []\n",
    "    for agent in agents:\n",
    "        eta_idx = f'eta_{agent.id}'\n",
    "        agent_obj = df_row[eta_idx]\n",
    "\n",
    "        for proba in agent.probabilities_ind:\n",
    "            u_idx = f'u_{agent.id}_{proba}'\n",
    "            w_idx = f'W_{agent.id}_{proba}'\n",
    "            j_idx = f'J_{agent.id}_{proba}'\n",
    "\n",
    "            agent_obj += (agent.alpha[proba] * df_row[j_idx]\n",
    "                        + agent.gamma[proba] * df_row[w_idx]\n",
    "                        + agent.probabilities[proba] / (1 - agent.risk_aversion) * df_row[u_idx])\n",
    "\n",
    "        res.append(agent_obj)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IC_utility_from_df_row(df_row, agents):\n",
    "    res = 0\n",
    "\n",
    "    for agent in agents:\n",
    "        for proba in agent.probabilities_ind:\n",
    "            j_idx = f'J_{agent.id}_{proba}'\n",
    "\n",
    "            res += - agent.alpha[proba] * df_row[j_idx] + agent.probabilities[proba] * df_row[j_idx]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = agents_list_optimistic_total(A_tilde, B_tilde, a, b, d, risk_aversion, probabilities, connection_matrix_2, d_target, g_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_objectives = []\n",
    "for _, row in df_without_IC.iterrows():\n",
    "    agent_objectives.append(agent_utility_from_df_row(row, agents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_param = df_param.to_dict()\n",
    "for i in range(community_size):\n",
    "    for trial_idx, trial in enumerate(agent_objectives):\n",
    "        dict_df_param[f'{i}'].update({(trial_idx, 'objective') : trial[i]})\n",
    "\n",
    "df_param = pd.DataFrame(dict_df_param).sort_index(level=0)\n",
    "df_param.to_csv(f'../data/without_IC_params_{2000}_with_obj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.401123621806084"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_IC.loc[0]['W_8_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc51f7b0a90f6051b3373596df13638ac01198d8ab4bced12ffaa78c40a2d902"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
